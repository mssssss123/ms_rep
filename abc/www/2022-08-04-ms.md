# 2022-08-04

# Paper Reading
|论文|总结|
|--|:-----|
|TABLEFORMER: Robust Transformer Modeling for Table-Text Encoding|现有的表格理解模型建模需要将表格结构线性化，但这样的做法会把行或列的顺序也建模进 去。这样做的问题在于会使模型容易受到行、列顺序变化造出的影响。并且之前的方法没有完全建模表格结构，阻碍了模型的理解能力。本文提出了一种鲁棒的、结构感知的table-text编码架构：TableFormer，能够不受行列顺序的影响，并通过可学习的attention机制更好的建模表格结构|
|Knowledge Graph Contrastive Learning for Recommendation|KG被作为item的辅助信息，提供推荐的质量。然而存在这样的问题：1.图谱中实体的长尾效应导致不能很好增强item表示2.图谱中存在偏离主题的噪声信息，从而影响捕捉用户偏好本文提出了一种通用的图谱对比学习方法进行推荐。首先采取一种relation-aware的知识聚合机制，来独立地去捕捉实体、关系的这种上下文信息来增强item表示。接下来通过cross-view对比学习的方式保留受噪声影响较小的item|
|Transformers4Rec: Bridging the Gap between NLP andSequential / Session-Based Recommendation|现有的工作已经证明在序列化推荐系统应用transformer架构的好处，但推荐系统领域对transformer架构的应用较为落后，本文提出一个可扩展的模型，能够方便推荐系统领域研究者快速应用HuggingFace的transformers库的最新成果。模型只使用了HF库中的transformer架构部分，并添加了推荐相关的结果。HF提供了用于nlp任务训练和评估的trainer class，本文的模型继承了这个类并重写了predict和evaluate方法用于推荐任务.|
|Leveraging Passage Retrieval with Generative Modelsfor Open Domain Quest|此前提出的用于开放域问答的生成模型不依赖外部知识而取得了不错的效果，但它的参数非常巨大而且信息都需要存储在权重中，使得模型训练成本很高。本文提出的fid模型，首先将检索到的支持passage和question拼接在一起然后独立地由encoder进行编码，之后将得到的每个evidence的编码向量拼接一起由decoder生成答案。本文提出的方法通过独立编码passage，使得只在一个context下计算注意力，减少了模型计算时间，并且在deocder部分融合检索到的evidence能够更好地生成答案。|
|Decoupled Side Information Fusion for SequentialRecommendation|将side information融入到序列推荐系统可以提高预测下一项的性能。作者通过实验分析发现，之前的工作在进入注意力层前，就将辅助信息embedding同item embedding集成在一起作为attention层的输入，限制了注意力矩阵的表示并且不同异构信息会对注意力计算带来干扰。基于此，作者提出了DIF-SR模型，将辅助信息embedding和item的整合移到attention层进行，通过分别对item以及它的各种属性embedding矩阵计算各自的注意力得分，并设计出一个函数来整合这些得分作为注意力得分，再乘到以原始item id矩阵得到的value矩阵。该方案减少了异构信息的干扰，增强了side information融合的建模能力。|

# Experiment
### 数据集整理
我统计了六种常用的具有文本信息的推荐数据集，具体内容介绍我写在ppt里面了。
|数据集|user|item|interaction|交互信息|文本信息|
|-|---:|---:|---:|----|-----|
|ml-1m|6040|3706|1000209|电影评分1-5|电影title、流派|
|ml-20m|138493|27278|20000263|电影评分1.0-5.0|电影title、流派|
|amazon-book|8026324|2330066|22507155|书籍评分1-5|产品元信息|
|lfm-1b|120322|32291134|1088161692|每个交互代表该用户听了这首歌，存在大量重复交互|曲目名称|
|book-crossing|278858|271379|1149780|书籍评分1-10|书名、作者|
|yelp|1987897|150346|6990280|对商家打星1-5|商家、用户信息|

### 模型
我统计了一下我看过的论文使用的数据集。
|模型|类型|数据集|辅助信息|
|---|----|----|---|
|RippleNet|知识图谱|ml-1m,book-crossing,bing-news|图谱|
|KGAT|知识图谱|amazon-book,last-fm,yelp|图谱|
|KGIN|知识图谱|amazon-book,last-fm,ifashion|图谱|
|KGCL|知识图谱|amazon-book,yelp，mind|图谱|
|Bert4Rec|序列化|ml-1m,ml-20m,beauty,steam|无|
|DIF-SR|序列化|beauty,sports,toys,yelp|产品元数据|
|DuoRec|序列化|ml-1m,yelp,amazon beauty clothing sports|无|
|Cohhn|会话|cosmetics,Diginetica-buy,Amazon|price|
|p5|.|sports,beauty,toys|产品元数据|

### KB4Rec
<https://github.com/RUCDM/KB4Rec#Ref-AmazonBook>
我发现最近的基于知识图谱的论文大部分喜欢使用kb4rec所提供的数据集。kb4rec提供了ml-20m，last-fm，amazon-book数据集中item在freebase中的对应entity id，可以很方便的进行知识图谱信息获取。我觉得可以用这三个数据集做，我可以先拿ml-1m这个小的数据集试验一下
