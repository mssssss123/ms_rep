# 2022-08-11

# Paper Reading
|论文|总结|
|--|:-----|
|FAVIQ: FAct Verification from Information-seeking Questions|本文提出了一种新的事实验证数据集，它通过人们现实中的存在歧义的搜索问题来生成claim，这种易混淆的现实问题，需要让模型更加充分理解evidence，使得数据集更具有挑战，同时实验结果也表明即使是现有模型也不能很好解决FAVIQ的问题。|
|Towards Unified Conversational Recommender Systems via Knowledge-Enhanced Prompt Learning|对话推荐系统的推荐和对话两个模块由于采用了不同的开发技术和体系结构，很难将它们无缝关联起来，因此存在着推荐和回复不一致的情况。本文受预训练语言模型的启发，用通用的方式设计两个模块，提出了UNICRS模型|
|KGAT: Knowledge Graph Attention Network for Recommendation|使用知识图谱作为辅助信息，将item和它的各种属性联系起来，而不是作为它的特征值。后续的工作大多follow本篇论文的setting|
|RecBole: Towards a Unified, Comprehensive and Efficient Framework for Recommendation Algorithms|近年已经有了大量的推荐算法，外界对于如何标准化推荐算法的开源实现的关注不断增加。本文提出了一个统一的推荐系统算法库，RecBole，在28个基准数据集上实现了73个推荐模型。|
|RecBole 2.0: Towards a More Up-to-Date Recommendation Library|在RecBole库的基础上，扩展了八个包，为促进推荐系统最新研究提供了宝贵的资源|

# Experiment

### 推荐系统开源库
RecBole是2021年开源的一个推荐系统算法库，提供了81种推荐系统模型的复现以及28种数据集的处理，我在调研论文的时候发现最近2022年的论文在基线模型比较时，大多直接使用该库提供的模型复现。
介绍<https://recbole.io/cn/index.html>
相关论文<https://arxiv.org/abs/2011.01731>
### 实验设置
《Revisiting Alternative Experimental Settings for Evaluating Top-N Item Recommendation Algorithms Analysis on Dataset Splitting》论文对于top-n item推荐的实验设置进行了一些探究，现总结如下表。
|实验|做法|结论|
|---|----|----|
|Analysis on Dataset Splitting|本文将交互记录的顺序方法划分为两种：Random Ordering(RO)：随机打乱，Temporal Ordering (TO)按时间戳顺序排序,数据集划分分为两种：Ratio-based Splitting (RS)：按比例划分训练集测试集验证集（本文按8：1：1）， Leave-one-out Splitting (LS)：选择一个ground-truth ite作为测试集，另一个作为验证集，剩余的items作为训练集|对上述方法组合为4种比较，item排序对性能影响更显著，其中随机打乱适用于一般推荐，而时间排序更适用于时间敏感的顺序推荐。其次对于数据集划分，更推荐比例划分，而leave-one-out更适用于小数据集|
|Analysis on Sampled Metrics|对于测试，将item集大小较大时，将item集中所有item作为候选item非常耗时，一种方法是将一小部分无关item进行采样，然后将ground-truth item和采样的item合并为单个候选列表进行排序，度量结果基于子集计算，这种方法叫做sampled metrics。本文比较两种，uniform sampling和popularity-biased sampling，进一步设置samples为10，50，100，即用一个ground-truth item去和它们去配对。|实验结构表明，如果非必要不用采样sampled metrics，如果一定需要，最好使用尽可能多的无关item|
|Analysis on Domain Selection|对amazon的多个domain数据集进行分析|最好使用来自多个不同领域的多个数据集作为评估集|
### 知识图谱
我调研了google学术中高引用的一些论文以及最近两年的基于知识图谱的论文。概括地讲，可以以KGAT这篇论文作为分水岭，在此之后的大部分论文都是follow它的setting，我想大致原因是在于kgat论文提供了它的图谱数据。movielen数据集数据相对密集，因此后续使用该数据的工作大多参考ripplenet设置了阈值为4，而其他数据集大多稀疏，因此对于显性评价直接转化。
|论文|数据集|数据集处理方式|图谱处理方式|评价指标|
|---|----|----|----|----|
|RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems|movielen-1m，book-crossing|将ml-1m评分大于等于4的视为隐性反馈1，而book-crossing所有评分都转化为1。同时对两个数据集中为每个用户采用与1等长的未交互item样本作为负例。数据集按照6:2:2进行划分|图谱:Microsoft Satori 链接方式:首先从整个KG中选择一个三元组子集，其关系名称包含“movie”或“Book”，置信水平大于0.9。给定子KG，我们通过将所有有效电影/书籍的名称与三元组的尾部（head、film.film.name、tail）或（head，Book.Book.title，tail）匹配来收集它们的ID。为简单起见，不包括没有匹配或多个匹配实体的项目。然后，将ID与所有KG三元组的头部和尾部匹配，从子KG中选择所有匹配良好的三元组，并将实体集迭代扩展到四跳|CTR预测：auc、acc  topk推荐： Precision@K, Recall@K, F1@K|
|KGAT: Knowledge Graph Attention Network for Recommendation|amazon-book，last-fm，yelp|amazon-book：保留至少十个交互的item和user，last-fm：时间戳2015.1-2015.6的数据集，同时也采用10core设置，yelp：使用2018年，将local businesses作为items，同时采样10core设置。对于每个数据集，我们随机选择每个用户80%的交互历史来构成训练集，并将剩余的作为测试集。从训练集中，我们随机选择10%的交互作为验证集，以调整超参数。对于每个观察到的用户项目交互，我们将其视为正实例，然后执行负采样策略，将其与用户之前未消费的一个负项目配对。在测试时，对于测试集中每个用户，将剩余未交互的所有item作为negative items，最后输出除训练集中positive items外所有item的偏好分数|amzon/lfm：按照kb4rec的链接，保留直接与item对齐的实体，并保存涉及item的两跳三元组，yelp：从the local business information network (e.g., category, location, and attribute)提取知识，考虑了涉及item的两跳的实体的三元组。为保证kg质量，过滤掉不常见的实体(出现次数少于10)，并保留至少在50个三元组中出现的realtion|topk：Recall@K，ndcg@k   k=20|
#### baseline model
|模型|类型|介绍|
|---|----|----|
|BPR|传统的协同过滤方法|用pariwise rank loss对候选item进行排序的代表性推荐方法|
|NCF|基于MLP的神经协同过滤|它利用多层感知器赋予该框架以非线性特征交互|
|GC-MC|用于协同过滤的图神经网络|它建立在图形自动编码架构上，以基于二分图中的链接捕获用户和项目之间的交互模式|
|LightGCN|用于协同过滤的图神经网络|这是一种最先进的基于GCN的推荐方法，简化了用户和项目之间消息传递过程中的卷积运算|
|SGL|自监督学习推荐系统|该方法通过增强基于图的CF框架和基于增强结构的自监督信号，提供了最先进的性能|
|CKE|Embedding-based Knowledge-aware Recommendation|该方法采用TransR对item的语义信息进行编码，并进一步将其纳入到带有知识库的item表示的去噪自动编码器中|
|RippleNet|Path-based Knowledge-aware Recommendation|它利用知识图谱中构建好的路径来聚合用户偏好。它是一种类似记忆的神经模型，用于改善用户表示|
|KGCN|KG-enhanced Recommendation with GNNs|它的目的是对KG中的语义信息进行高阶相关上下文编码。KGCN的核心是将邻域信息偏差合并到聚合消息中，用于实体表示|
|KGAT|KG-enhanced Recommendation with GNNs|该模型在知识感知的协同图上设计了一个基于注意力的消息传递方案，用于embedding融合。在聚合过程中对于每个邻居节点的聚合比重不同|
|KGIN|KG-enhanced Recommendation with GNNs|它是最近提出的KG增强推荐模型，用于识别用户的潜在意图，并进一步对用户-intent-item和KG三元组执行关系路径感知聚合|
|CKAN|KG-enhanced Recommendation with GNNs|它的目的是对KG中的语义信息进行高阶相关上下文编码。KGCN的核心是将邻域信息偏差合并到聚合消息中，用于实体表示|
|MVIN|KG-enhanced Recommendation with GNNs|它是一种基于图形神经结构的多视图项嵌入网络。来自用户和实体的信息被视为学习item的特征嵌入。|

### Sequential Recommendation
感觉序列化这边有点乱，没有太多被follow的一个工作，我统计了几篇高引用的论文。
|论文|数据集|数据集处理方式|评价指标|
|---|----|----|----|
|BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer|amzon beauty,steam,ml-1m/ml-20m|将所有隐性反馈转化为1，按用户对交互记录进行分组，并根据时间戳进行排序，为用户构建交互序列，每个用户至少5个交互.采用leave-one-out评估，但我在阅读源码时发现一个问题，它的验证集直接拼在训练集上，然后一起同时进行。将测试集中的每个ground-truth item与100个随机抽样的用户未交互的negative item配对。根据受欢迎程度对这100个negative item进行抽样。因此，任务变成用每个用户的ground-truth item和这些negative item进行排序|HR NDCG MRR 报告了k=1、5、10的HR和NDCG|
|Hierarchical Gating Networks for Sequential Recommendation|ml-20m,amazon books,amazon cds| 为了与隐式反馈设置保持一致，将评分不低于四分（五分之一）的评分保留为正反馈.并将所有其他评分视为所有数据集上的缺失条目。为了过滤嘈杂的数据，让用户至少有10个评级，而项目至少有5个评级.对于每个用户，我们将用户序列中70%的交互作为训练集，并将接下来10%的交互用作超参数调优的验证集。剩下的20%构成了报告模型性能的测试集。请注意，在测试过程中，输入序列包括训练集和验证集中的交互|ndcg@k recall@k|
|S3-Rec: Self-Supervised Learning for Sequential Recommendation with Mutual Information Maximization|Amazon Beauty, Sports, and Toys,yelp,last-fm|amazon:使用商品品牌，类别属性 yelp:使用业务类别 lastfm:使用音乐家标签。数据集5-core设置，采用了遗漏策略进行评估。将ground truth item与99个随机抽样的用户未交互的negative item配对。我们根据item排名计算所有指标，并报告所有测试用户的平均得分|HR@k  NDCG@k  MRR|
|Self-Attentive Sequential Recommendation|amazon beauty、games,steam,ml-1m|将所有隐性反馈视为交互，并采用5-core进行过滤，用leave-one-out策略进行划分数据|hit@k，ndcg@k|
|Contrastive Learning for Representation Degeneration Problem in Sequential Recommendation|Amazon Beauty, Clothing and Sports，MovieLens-1M，yelp|yelp:我们的实验使用了2019年1月1日之后的交易记录.所有交互都被视为隐式反馈。出现次数少于五次的用户或项目将被删除。序列的最大长度为50|HR@k NDCG@k|
|Contrastive Learning for Sequential Recommendation|Beauty,Sports,Yelp,ML-1M|yelp:仅使用2019年1月1日之后的交易记录.我们将所有数字评级或评论的出现转换为“1”，其他转换为“0”。然后，对于每个用户，我们丢弃重复的交互，然后按交互时间步长按时间顺序对其历史item进行排序，以获得用户交互序列。只保留“5核”数据集,采用leave-one-out。为了加快度量的计算速度，以前的许多工作都使用采样度量，并且仅使用较小的随机item集对相关item进行排序。然而，这种采样操作可能会导致与非采样版本不一致。因此，我们在整个item集上评估每种方法，而不进行抽样，并根据用户未交互的所有item的相似度得分对其进行排序|hr，ndcg|
#### baseline model
|模型类型|类型|介绍|
|---|----|---|
|pop|通用方法，不考虑动作顺序|这是一个非个性化的方法，为每个用户推荐相同的item，这些item是整个item集中交互次数最多最受欢迎的item|
|BPR|通用方法，不考虑动作顺序|第一种利用BPR损失训练矩阵分解模型的方法|
|GRU4REC|深度学习的顺序推荐系统|应用GRU对用户序列进行建模。这是第一个顺序推荐的recurrent模型|
|Caser|深度学习的顺序推荐系统|是一种基于CNN的方法，通过对顺序推荐应用水平和垂直卷积运算来捕获高阶模式|
|SASRec|深度学习的顺序推荐系统|是一种单向的自注意模型。这是顺序推荐中的一个强有力的基线|
|BERT4Rec|深度学习的顺序推荐系统|使用掩蔽项训练方案模拟NLP中的掩蔽语言模型。主干是双向的自我注意机制|
|S3RecMIP|深度学习的顺序推荐系统|掩蔽对比预训练。这里使用掩码项预测（MIP）变体|
|CL4SRec|深度学习的顺序推荐系统|掩蔽对比预训练。这里使用掩码项预测（MIP）变体|


# 请假
周一开始，鼻炎犯了，一直打喷嚏流鼻涕。我想明天组会请个假，休息几天