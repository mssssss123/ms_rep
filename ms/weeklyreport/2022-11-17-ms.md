# 2022-11-17

# Paper Reading
|论文|总结|
|--|:-----|
|Language Models as Recommender Systems:Evaluations and Limitations|本文将推荐任务转换为multi token的预测任务，设计了一种prompt：a user watched A,B,..,now the user want to watch Masked.本文给出的启示：1.模型的尺寸和prompt设计对性能微小 2.multi-token预测对模型有挑战，特别是电影题目长度不一 3.zero-shot有竞争力，但微调效果不如传统方法|
|Personalized Prompt Learning for ExplainableRecommendation|由于id向量是随机初始化，和预训练语言模型的词向量存在差异，因为过往做法大多使用rnn模型或未预训练过的小型transformer模型，对预训练语言模型的探索较少。挑战1:预训练语言模型难以改变其架构 方法：采用prompt去适应。挑战2:模型已经训练好，id向量为随机初始化，不能通过梯度下降取得很好效果 方法：1.第一阶段随机初始化user和item向量。固定住模型去训练id向量，之后再更新参数 第二阶段 共同训练 2.使用用户的评分作为监督信号 |
|On the Sentence Embeddings from Pre-trained Language Models|bert对句子进行编码的向量存在各向异性，向量值会受句子中词在所有训练语料里的词频影响，导致高频词编码的句向量距离更近，更集中在原点附近。这会导致即使一个高频词和一个低频词的语义是等价的，但词频的差异也会带来很大的距离偏差，从而词向量的距离就不能很好地代表语义相关性,标准高斯分布是各向同性的,作者认为可以利用标准化流(Normalizing Flows)将BERT句向量分布变换成一个光滑的，各向同性的标准高斯分布|
|M6-Rec: Generative Pretrained Language Models areOpen-Ended Recommender Systems|将用户行为完全转化为纯文本如“A male user in Beijing, who clicked product X last night and product Y this noon, was recommended product Z and did not click it. ”。设计了一种框架，分别用处理用户行为文本和候选商品文本，并分别表示为向量作下游任务|
|Recommender Transformers with Behavior Pathways|本文提到序列化推荐的一大问题是利用以往的所有行为，而这些历史交互信息存在着大量与当前时刻无关的信息。本文引入pathway注意力机制，通过修改当前时刻的query，动态地去控制当前参与注意力得分的token，从而让预测的序列信息更加准确|

# Experiment


### 1.实验结果

<https://docs.google.com/spreadsheets/d/1TKLdfQsZdasF7FEloFOW_PshGhmkk0ULeUN0nGNn5BU/edit#gid=0>

### 2.yelp数据集

yelp数据集上我跑了两组实验，一组是只使用name作为文本，一组是使用name和address作为文本。引入了address作为辅助信息效果更好，目前比GRU4Rec、Caser、Gru4RecF、SASRecF效果要好，但没有Bert4Rec和SASRec效果好。

tensorboard:

<https://tensorboard.dev/experiment/4Or38khLQuGik2fRbUjNVA/#scalars>

输入文本格式：

name:

序列：
```
"Here is the visit history list of user: The Great Greek, Astoria Cafe & Market, Chico Malo, Windsor, Izzy's Bakery & Cafe recommend next item"
```
商品：
```
'Starlite BBQ'
```

name+address:

序列：
```
"Here is the visit history list of user: title: The Great Greek address: 1275 W Warm Springs Rd, Ste 160 Henderson NV, title: Astoria Cafe & Market address: 5417 Detroit Ave Cleveland OH, title: Chico Malo address: 50 W Jefferson St, Ste 100 Phoenix AZ, title: Windsor address: 5223 N Central Ave Phoenix AZ, title: Izzy's Bakery & Cafe address: 1870 W Main St Mesa AZ recommend next item"
```
商品：
```
'title: Starlite BBQ address: 7620 E Indian School Rd, Ste 101 Scottsdale AZ'
```

### 3.Amazon Beauty数据集

amazon的数据集和yelp不同，它的item名字文本与其说是名字更像是对商品的简短描述。beauty数据集上我跑了四组实验，一组是只使用name作为文本，一组是我舍弃name用category+brand作为文本，一组是name+category，一组是name+brand。实验结果表面name的信息很重要，而舍弃name效果并不好。加入brand文本信息和category文本信息后效果都有提升，目前最好的是name+category作为文本，比GRU4Rec、Caser、Gru4RecF、Bert4Rec效果好。

tensorboard:

<https://tensorboard.dev/experiment/g2SMF42CQD6Mqray2nlbkQ/#scalars>

### 4.yelp数据集hard negative

我在yelp数据集上对模型加入hard negative进行训练进行了实验。首先我load目前在name+address上取得最好效果的checkpoint，分别在训练集和验证集上对所有的item进行inference，保存top100的索引。之后我跑了两组实验，第一组是保留每个query对应的top20并去掉对应的pos，训练采用1个pos和7个hard negative(每次从top20随机取)，第二组是保留每个query对应的top100并去掉pos，训练采用1个pos和9个hard negative(每次从top20随机取)。后者的效果要好一些，但都很糟糕，我发现不管是train loss还是dev loss都很难降下来。

tensorboard:

<https://tensorboard.dev/experiment/m2K2HB8wR4ylurYqbgEptg/#scalars>