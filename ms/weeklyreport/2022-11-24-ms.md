# 2022-11-24

# Paper Reading
|论文|总结|
|--|:-----|
|WHERE TO GO NEXT FOR RECOMMENDER SYSTEMS? ID- VS. MODALITY-BASED RECOMMENDER MODELS REVISITED|本文探究了将id作为推荐标识符替换的可能性，本文表明：1.对于使用单个用户id，用序列建模用户表示效果更好 2.对比双塔模型dssm架构，sasrec应用到其他模态（文本、图片）编码器效果能比id要好3.文本或图片更适合冷启动场景4.使用文本或图片代替id可以继承nlp和cv的最新进展。本文只考虑了单模态下的item编码情况，并且只是选取了两个典型的推荐模型进行改进和其本身进行比较，是否能优于基于id的sota模型未知|
|Chain-of-Thought Prompting Elicits Reasoning in Large Language Models|本文介绍了一种叫做推理链的思想，通过在输入输出中间加入推理过程的提示，使得模型能够在数学计算、常识推理上提高性能|
|A Win-win Deal: Towards Sparse and Robust Pre-trained Language Models|plm的问题在于参数量大以及容易受下游数据集偏见的影响。本文对bert模型进行了迭代权重剪枝训练，验证了bert子网络的确存在着稀疏和鲁棒性 |
|A Context-Enhanced Transformer with Abbr-Recover Policy for Chinese Abbreviation Prediction|中文缩略词任务不同于英文通常的缩写，是一个更具挑战的任务，因为形式更加复杂。现有的做法是对每个token做二分类任务，然而这只利用了实体本身的文本信息。本文将实体缩略任务转换为一个从全称到缩写的机器翻译任务，将实体相关的文本信息也作为输入，并在decoder端后加入了两个分类器，用来判别token是省去还是保留|
|Real-time Personalization using Embeddings for Search Ranking at Airbnb|本篇论文是基于业务理解来去选择负样本，对于租房的推荐任务，将与正样本同城市的房间作为了负样本，我觉得yelp数据集也可以考虑这样选取负样本|

# Experiment


### 实验结果

<https://docs.google.com/spreadsheets/d/1TKLdfQsZdasF7FEloFOW_PshGhmkk0ULeUN0nGNn5BU/edit#gid=0>


### 实验设置

因为我们现在存在一个问题就是in-batch negative做法让序列看到的商品数太少了，所以我采用再加一些负样本。我采用了inbatch+random negative和inbatch+popular negative两组实验。batch size设置为8，而每个序列我为它匹配10个商品（1个pos+9个neg），相较于之前的inbatch，batch size16，我们现在可以每次让序列见到80个商品。经过实验，我发现采取in batch+random的效果非常好，效果较之前inbatch的性能有了很多提升，已经接近sota模型的效果。

但是，popular negative的效果不是很好。我按照数据集中item出现的频率对他由高到低进行了排序，之后我保留top20000，为每个序列从中随机取100个popular item（去掉当前序列交互过以及要预测的正样本item）作为负样本。random negative是为每个序列随机取100个 random item（去掉当前序列交互过以及要预测的正样本item）作为负样本，实验结果表明random的效果更好。可能每个序列都匹配top2000的流行商品重复度太高？我不是很确定。。

另外，我发现从结果看recall的表现很好，而ndcg效果不佳，似乎更擅长召回而不是排序，我在打印模型预测结果时看到它预测的高排名一般都是它序列交互商品本身，而beauty数据集没有yelp数据集很少有重复交互的现象，因此似乎这个是ndcg排序效果不好的原因。

amazon-beauty数据tensorboard：<https://tensorboard.dev/experiment/Yzqg3SjvT3GyKjOb46CVWg/>

yelp数据集tensorboard：<https://tensorboard.dev/experiment/tR3ioy4ETNadbw92Qe4QXw/#scalars>

### hard negative
这周我看了下上周最好的checkpoint预测的top20.我发现模型的倾向是预测与序列最后几个item相近的item，一般排在前面的是他们本身，然后是同一品牌的商品。看起来预测的也很正常。但选它们作为hard negative效果不是很好。我的做法是从top100中去掉预测的item，之后每次从中随机选取。我觉得应该把当前序列交互过的商品也去掉再试试（beauty数据集不存在重复交互）。

例如：

|模型|Recall@10|
|-----|-----|
|序列|title: Jason Pure Natural Hand Soap, Purifying Tea Tree, 16 Ounce category: Beauty, Skin Care, Hands & Nails, Hand Soaps|
|目标item|title: Jason Thin-To-Thick Extra Volume Shampoo, 8 Ounce category: Beauty, Hair Care, Shampoos|
|top1|title: Jason Pure Natural Hand Soap, Purifying Tea Tree, 16 Ounce category: Beauty, Skin Care, Hands & Nails, Hand Soaps|
|top2|title:Jason Pure Natural Shampoo, Restorative Biotin, 16 Ounce category: Beauty, Hair Care, Shampoos|
|top3|title:Jason Pure Natural Moisturizing Creme, Anti-Aging Tea Time, 4 Ounce category: Beauty, Skin Care, Face, Creams & Moisturizers, Fluids & Lotions, Lotions|
|top4|title:Jason Purifying Tea Tree Body Wash 30 fl oz category: Beauty, Bath & Body, Cleansers, Body Washes|
|top5|title: Jason Pure Natural Conditioner, Restorative Biotin, 16 Ounce category: Beauty, Hair Care, Conditioners|

### 下一步
根据之前的实验分析，加入category、brand、address等文本效果都会有提升，因此我需要做的是对序列端和商品端都加入这些描述信息。同时由于显存限制以及编码长度限制，我目前对于序列采取了倒着截断256个token（保留最近交互），而商品正着截断到32个token（尽可能保留完整商品名字）。但根据checkpoint预测结果，模型对于预测item非常倾向于最后交互，但有时它并不是和最近的相关，因此我觉得应该纳入更多的序列信息。
